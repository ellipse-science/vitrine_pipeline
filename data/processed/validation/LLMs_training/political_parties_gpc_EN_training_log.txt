[LOG] Début de l'enregistrement des logs pour political_parties_gpc_EN en EN
Données chargées pour political_parties_gpc en EN
Distribution des labels en entraînement pour political_parties_gpc en EN :
label
0    15597
1        2
Name: count, dtype: int64
Distribution des labels en validation pour political_parties_gpc en EN :
label
0    3899
1       1
Name: count, dtype: int64
label ids: {0: 0, 1: 1}
label ids: {0: 0, 1: 1}
Encodage des données terminé.
Sauvegarde du modèle dans : political_parties_gpc_EN.model

======== Epoch 1 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:18.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:14.
  Batch   240  of    488.    Elapsed: 0:03:53.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:10.
  Batch   360  of    488.    Elapsed: 0:05:49.
  Batch   400  of    488.    Elapsed: 0:06:28.
  Batch   440  of    488.    Elapsed: 0:07:07.
  Batch   480  of    488.    Elapsed: 0:07:45.

  Average training loss: 0.01
  Training took: 0:07:52

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 2 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:15.
  Batch   240  of    488.    Elapsed: 0:03:54.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:11.
  Batch   360  of    488.    Elapsed: 0:05:50.
  Batch   400  of    488.    Elapsed: 0:06:28.
  Batch   440  of    488.    Elapsed: 0:07:07.
  Batch   480  of    488.    Elapsed: 0:07:46.

  Average training loss: 0.00
  Training took: 0:07:53

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 3 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:15.
  Batch   240  of    488.    Elapsed: 0:03:53.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:11.
  Batch   360  of    488.    Elapsed: 0:05:49.
  Batch   400  of    488.    Elapsed: 0:06:28.
  Batch   440  of    488.    Elapsed: 0:07:07.
  Batch   480  of    488.    Elapsed: 0:07:46.

  Average training loss: 0.00
  Training took: 0:07:53

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 4 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:15.
  Batch   240  of    488.    Elapsed: 0:03:53.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:11.
  Batch   360  of    488.    Elapsed: 0:05:49.
  Batch   400  of    488.    Elapsed: 0:06:28.
  Batch   440  of    488.    Elapsed: 0:07:06.
  Batch   480  of    488.    Elapsed: 0:07:45.

  Average training loss: 0.00
  Training took: 0:07:52

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 5 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:15.
  Batch   240  of    488.    Elapsed: 0:03:53.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:11.
  Batch   360  of    488.    Elapsed: 0:05:50.
  Batch   400  of    488.    Elapsed: 0:06:28.
  Batch   440  of    488.    Elapsed: 0:07:07.
  Batch   480  of    488.    Elapsed: 0:07:46.

  Average training loss: 0.00
  Training took: 0:07:53

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 6 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:15.
  Batch   240  of    488.    Elapsed: 0:03:53.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:10.
  Batch   360  of    488.    Elapsed: 0:05:49.
  Batch   400  of    488.    Elapsed: 0:06:28.
  Batch   440  of    488.    Elapsed: 0:07:07.
  Batch   480  of    488.    Elapsed: 0:07:45.

  Average training loss: 0.00
  Training took: 0:07:52

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 7 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:15.
  Batch   240  of    488.    Elapsed: 0:03:53.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:11.
  Batch   360  of    488.    Elapsed: 0:05:49.
  Batch   400  of    488.    Elapsed: 0:06:28.
  Batch   440  of    488.    Elapsed: 0:07:07.
  Batch   480  of    488.    Elapsed: 0:07:45.

  Average training loss: 0.00
  Training took: 0:07:53

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 8 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:15.
  Batch   240  of    488.    Elapsed: 0:03:53.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:11.
  Batch   360  of    488.    Elapsed: 0:05:50.
  Batch   400  of    488.    Elapsed: 0:06:28.
  Batch   440  of    488.    Elapsed: 0:07:07.
  Batch   480  of    488.    Elapsed: 0:07:46.

  Average training loss: 0.00
  Training took: 0:07:53

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 9 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:15.
  Batch   240  of    488.    Elapsed: 0:03:54.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:11.
  Batch   360  of    488.    Elapsed: 0:05:50.
  Batch   400  of    488.    Elapsed: 0:06:28.
  Batch   440  of    488.    Elapsed: 0:07:07.
  Batch   480  of    488.    Elapsed: 0:07:46.

  Average training loss: 0.00
  Training took: 0:07:53

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 10 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:15.
  Batch   240  of    488.    Elapsed: 0:03:54.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:11.
  Batch   360  of    488.    Elapsed: 0:05:50.
  Batch   400  of    488.    Elapsed: 0:06:28.
  Batch   440  of    488.    Elapsed: 0:07:07.
  Batch   480  of    488.    Elapsed: 0:07:46.

  Average training loss: 0.00
  Training took: 0:07:53

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 11 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:15.
  Batch   240  of    488.    Elapsed: 0:03:53.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:11.
  Batch   360  of    488.    Elapsed: 0:05:49.
  Batch   400  of    488.    Elapsed: 0:06:28.
  Batch   440  of    488.    Elapsed: 0:07:07.
  Batch   480  of    488.    Elapsed: 0:07:45.

  Average training loss: 0.00
  Training took: 0:07:53

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 12 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:15.
  Batch   240  of    488.    Elapsed: 0:03:53.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:11.
  Batch   360  of    488.    Elapsed: 0:05:49.
  Batch   400  of    488.    Elapsed: 0:06:28.
  Batch   440  of    488.    Elapsed: 0:07:07.
  Batch   480  of    488.    Elapsed: 0:07:45.

  Average training loss: 0.00
  Training took: 0:07:53

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 13 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:15.
  Batch   240  of    488.    Elapsed: 0:03:53.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:11.
  Batch   360  of    488.    Elapsed: 0:05:49.
  Batch   400  of    488.    Elapsed: 0:06:28.
  Batch   440  of    488.    Elapsed: 0:07:07.
  Batch   480  of    488.    Elapsed: 0:07:45.

  Average training loss: 0.00
  Training took: 0:07:53

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 14 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:14.
  Batch   240  of    488.    Elapsed: 0:03:53.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:10.
  Batch   360  of    488.    Elapsed: 0:05:49.
  Batch   400  of    488.    Elapsed: 0:06:28.
  Batch   440  of    488.    Elapsed: 0:07:06.
  Batch   480  of    488.    Elapsed: 0:07:45.

  Average training loss: 0.00
  Training took: 0:07:52

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 15 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:15.
  Batch   240  of    488.    Elapsed: 0:03:53.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:11.
  Batch   360  of    488.    Elapsed: 0:05:49.
  Batch   400  of    488.    Elapsed: 0:06:28.
  Batch   440  of    488.    Elapsed: 0:07:07.
  Batch   480  of    488.    Elapsed: 0:07:46.

  Average training loss: 0.00
  Training took: 0:07:53

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 16 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:57.
  Batch   160  of    488.    Elapsed: 0:02:36.
  Batch   200  of    488.    Elapsed: 0:03:15.
  Batch   240  of    488.    Elapsed: 0:03:53.
  Batch   280  of    488.    Elapsed: 0:04:32.
  Batch   320  of    488.    Elapsed: 0:05:11.
  Batch   360  of    488.    Elapsed: 0:05:50.
  Batch   400  of    488.    Elapsed: 0:06:30.
  Batch   440  of    488.    Elapsed: 0:07:09.
  Batch   480  of    488.    Elapsed: 0:07:48.

  Average training loss: 0.00
  Training took: 0:07:55

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 17 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:58.
  Batch   160  of    488.    Elapsed: 0:02:37.
  Batch   200  of    488.    Elapsed: 0:03:16.
  Batch   240  of    488.    Elapsed: 0:03:55.
  Batch   280  of    488.    Elapsed: 0:04:34.
  Batch   320  of    488.    Elapsed: 0:05:13.
  Batch   360  of    488.    Elapsed: 0:05:52.
  Batch   400  of    488.    Elapsed: 0:06:31.
  Batch   440  of    488.    Elapsed: 0:07:10.
  Batch   480  of    488.    Elapsed: 0:07:49.

  Average training loss: 0.00
  Training took: 0:07:56

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:22
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 18 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:41.
  Batch    80  of    488.    Elapsed: 0:01:20.
  Batch   120  of    488.    Elapsed: 0:01:59.
  Batch   160  of    488.    Elapsed: 0:02:38.
  Batch   200  of    488.    Elapsed: 0:03:17.
  Batch   240  of    488.    Elapsed: 0:03:56.
  Batch   280  of    488.    Elapsed: 0:04:35.
  Batch   320  of    488.    Elapsed: 0:05:14.
  Batch   360  of    488.    Elapsed: 0:05:53.
  Batch   400  of    488.    Elapsed: 0:06:32.
  Batch   440  of    488.    Elapsed: 0:07:11.
  Batch   480  of    488.    Elapsed: 0:07:50.

  Average training loss: 0.00
  Training took: 0:07:57

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:23
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 19 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:58.
  Batch   160  of    488.    Elapsed: 0:02:38.
  Batch   200  of    488.    Elapsed: 0:03:17.
  Batch   240  of    488.    Elapsed: 0:03:56.
  Batch   280  of    488.    Elapsed: 0:04:35.
  Batch   320  of    488.    Elapsed: 0:05:14.
  Batch   360  of    488.    Elapsed: 0:05:53.
  Batch   400  of    488.    Elapsed: 0:06:32.
  Batch   440  of    488.    Elapsed: 0:07:11.
  Batch   480  of    488.    Elapsed: 0:07:50.

  Average training loss: 0.00
  Training took: 0:07:57

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:23
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


======== Epoch 20 / 20 ========
Training...
  Batch    40  of    488.    Elapsed: 0:00:40.
  Batch    80  of    488.    Elapsed: 0:01:19.
  Batch   120  of    488.    Elapsed: 0:01:58.
  Batch   160  of    488.    Elapsed: 0:02:37.
  Batch   200  of    488.    Elapsed: 0:03:16.
  Batch   240  of    488.    Elapsed: 0:03:55.
  Batch   280  of    488.    Elapsed: 0:04:34.
  Batch   320  of    488.    Elapsed: 0:05:13.
  Batch   360  of    488.    Elapsed: 0:05:52.
  Batch   400  of    488.    Elapsed: 0:06:31.
  Batch   440  of    488.    Elapsed: 0:07:10.
  Batch   480  of    488.    Elapsed: 0:07:49.

  Average training loss: 0.00
  Training took: 0:07:57

Running Validation...

  Average test loss: 0.00
  Validation took: 0:00:23
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3899
           1       0.00      0.00      0.00         1

    accuracy                           1.00      3900
   macro avg       0.50      0.50      0.50      3900
weighted avg       1.00      1.00      1.00      3900


Training complete!
Entraînement terminé pour political_parties_gpc_EN
